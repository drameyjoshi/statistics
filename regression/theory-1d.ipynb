{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17091911-884b-42fe-bdc6-95713ea8168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5feeff9-cefe-439e-8ccd-98382460e329",
   "metadata": {},
   "source": [
    "This cell has $\\LaTeX$ commands.\n",
    "$$\n",
    "\\newcommand{\\E}{\\text{E}}\n",
    "\\newcommand{\\var}{\\text{Var}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39cd56a-47b5-4f39-a164-8efbf220c6cb",
   "metadata": {},
   "source": [
    "In the regression model,\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i,\n",
    "$$\n",
    "the terms $\\beta_0 + \\beta_1 X_i$ form the systematic part and $\\epsilon_i$ is called noise. $\\epsilon_i$ are assumed to be iid $N(0, \\sigma^2)$. Therefore,\n",
    "$$\n",
    "\\E(Y_i) = \\beta_0 + \\beta_1\\E(X_i) + 0\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\var(Y_i\\;|\\;X_i = x_i) = 0 + \\beta_1\\times 0 + \\sigma^2 = \\sigma^2.\n",
    "$$\n",
    "Thus, $Y_i\\;|\\; X_i = x_i \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2)$. It can be shown that under the assumption of gaussian noise, the maximum likelihood estimates of $\\beta_0$ and $\\beta_1$ are the least square estimates\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\beta}_1 &=& S_{xy}\\frac{S_y}{S_x} \\\\\n",
    "\\hat{\\beta}_0 &=& \\bar{Y} - \\hat{\\beta}_1\\bar{X}\n",
    "\\end{eqnarray}\n",
    "For a given data, the regression analysis gives an estimates of the true parameters of the regression model.\n",
    "\n",
    "Although the intercept is of mathematical interest it may not be important for the problem at hand.  That could be the reason by `statsmodel.api.OLS` does not add an intercept by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3b7f6-0b53-4dd8-8507-748c11ed408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'diamond.csv'\n",
    "filepath = os.path.join('.', 'datasets', dataset)\n",
    "\n",
    "if os.path.isfile(filepath):\n",
    "    df: pd.core.frame.DataFrame = pd.read_csv(filepath)\n",
    "else:\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860bbfd-07c4-46d5-b3bf-094fe3889648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba127d74-dd55-45bf-9ddf-de147133b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = sm.OLS(endog = df['price'], exog = sm.add_constant(df['carat']))\n",
    "result_1 = model_1.fit()\n",
    "result_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38975e-d86a-4782-a5f8-f16f7a6563b6",
   "metadata": {},
   "source": [
    "For this data, the estimate of the intercept is $\\hat{\\beta}_0 = -259.63$. It is interpreted as the price of a zero carat diamond. This statement, althought correct from the perspective of the regression model, is meaningless to a diamond trader. To avoid problems likes these, one shift the origin to the point $(\\bar{X}, 0)$ and interprets the intercept at the price of an 'average' diamond. We build such a model in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016e9a7-c245-40a1-9096-7df6ad04ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = sm.OLS(endog = df['price'], exog = sm.add_constant(df['carat'] - df['carat'].mean()))\n",
    "result_2 = model_2.fit()\n",
    "result_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b412a7-718c-4e36-9412-999fc8a5054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newX = [0.16, 0.27, 0.34]\n",
    "newX = newX - df['carat'].mean()\n",
    "new_data = pd.DataFrame({'carat': newX})\n",
    "result_2.predict(sm.add_constant(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bfbf2c-1dfc-4d7b-965d-310617390dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df['carat'], y=df['price'])\n",
    "plt.plot(df['carat'], result_2.predict(), color='black', linestyle='--', label='regression')\n",
    "plt.xlabel('carat')\n",
    "plt.ylabel('price')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da5f8a-c04a-486b-b1f6-c25326b56ec6",
   "metadata": {},
   "source": [
    "Refer to [an answer on Stackexchange](https://stats.stackexchange.com/questions/16493/difference-between-confidence-intervals-and-prediction-intervals) to understand the difference between confidence interval and prediction interval."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

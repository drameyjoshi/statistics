---
title: "Random Forest"
author: "Amey Joshi"
date: "19/12/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
```

## A few trials
We will build a few random forest models to predict the sale price. We continue
to use the training data. Let us first read the model data and choose a few
predictors.
```{r}
model.data <- readRDS("model_data.Rds")
all.predictors <- colnames(model.data)[-c(1, 13)]
```

It is not possible to use all variables because of limitations on the total
number of levels that the random forest algorithm can handle. We can examine 
the number of levels in every variable using
```{r}
sort(sapply(sapply(model.data, levels), length))
```

It helps to build a cumulative sum so that we know which variables to include.
```{r}
cumsum(sort(sapply(sapply(model.data, levels), length)))
```

We build our first model using the following predictors.
```{r}
selected.predictors <-
  c(
    "Neighborhood.1",
    "OverallQual.1",
    "Functional.1",
    "Foundation",
    "SaleCondition.1",
    "HeatingQC",
    "TotRmsAbvGrd",
    "TotalBsmtSF"
  )
rf.2 <- randomForest(
  reformulate(response = "SalePrice",
              termlabels = selected.predictors),
  data = model.data,
  importance = TRUE
)
pred.2 <- predict(rf.2, model.data)
plot(
  model.data$SalePrice,
  pred.2,
  xlab = "Actual price",
  ylab = "Est. price",
  main = "Predicted v actual sale price (V2)",
  cex = 0.3,
  col = 2
)
abline(a = 0, b = 1, lty = 2)
```

The fit is not bad. But it would be nice if we can narrow its spread around the 
dashed line and even make it even on either sides of the line. A summary of the 
difference is
```{r}
summary(pred.2 - model.data$SalePrice)
```

Let us add another numerical variable and also increase the number of trees.
```{r}
selected.predictors <- c(selected.predictors, "GrLivArea")
rf.4 <-  randomForest(
  reformulate(response = "SalePrice",
              termlabels = selected.predictors),
  data = model.data,
  importance = TRUE,
  ntree = 2000
)
pred.4 <- predict(rf.4, model.data)
plot(
  model.data$SalePrice,
  pred.4,
  xlab = "Actual price",
  ylab = "Est. price",
  main = "Predicted v actual sale price (V4)",
  cex = 0.3,
  col = 4
)
abline(a = 0, b = 1, lty = 2)
```

The points are spread in a narrower range around the dashed line. A summary of 
the difference between the actual and the predicted values is
```{r}
summary(pred.4 - model.data$SalePrice)
```

A nice way to compare the differences is by plotting them.
```{r}
plot(density(pred.4 - model.data$SalePrice), main = "Deviations of 2 models")
lines(density(pred.2 - model.data$SalePrice), lty = 2, col = 2)
legend("topright",
       legend = c("Version 2", "Version 4"),
       lty = c(2, 1),
       col = c(2, 1),
       cex = 0.7)
```

Version 4 has a taller and narrower peak aroung the centre. It is a better model
than version 2.


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the three files: clients.csv, loans.csv, payments.csv. These files are related by the following:\n",
    "1. The clients file is the parent of the loans file. Each client can have multiple distinct loans. The client_id column links the two files\n",
    "2. The loans file is the child of the clients file and the parent of the payments file. Each loan can have multiple distinct payments associated with it. The loan_id column links the two files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above datasets, answer the following questions. Show the steps taken to produce your final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all packages I will need for answering all questions.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import stats # To run ANOVA.\n",
    "import random                 # To select samples.\n",
    "from patsy import dmatrices   # To build design matrices.\n",
    "import statsmodels.api as sm  # Statistical models.\n",
    "import statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the three CSV files into dataframes. Check their structure, shape and desribe their statistics. Examine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files.\n",
    "clients = pd.read_csv('clients.csv')\n",
    "loans = pd.read_csv('loans.csv')\n",
    "payments = pd.read_csv('payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check their structure.\n",
    "clients.info()\n",
    "loans.info()\n",
    "payments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print their shapes.\n",
    "print(f'clients: {clients.shape}')\n",
    "print(f'loans: {loans.shape}')\n",
    "print(f'payments: {payments.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all columns with a data into datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients['joined'] = pd.to_datetime(clients['joined'])\n",
    "loans['loan_start'] = pd.to_datetime(loans['loan_start'])\n",
    "loans['loan_end'] = pd.to_datetime(loans['loan_end'])\n",
    "\n",
    "# Check their structure.\n",
    "clients.info()\n",
    "loans.info()\n",
    "payments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forgot to convert payment_date in payments.\n",
    "payments['payment_date'] = pd.to_datetime(payments['payment_date'])\n",
    "payments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Give the 5 client IDs with the highest mean payment amount\n",
    "2. How many unique loans have been given out to clients who joined prior to 2001?\n",
    "3. What is the mean number of payments missed by clients with a credit score of less than 700 and who have missed more than 50 payments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the 5 client IDs with the highest mean payment amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_ids with highest mean payment amount.\n",
    "highest_loan_ids = payments[['loan_id', 'payment_amount']]. \\\n",
    "                   groupby('loan_id'). \\\n",
    "                   mean(). \\\n",
    "                   sort_values(ascending=False, by='payment_amount'). \\\n",
    "                   head(5)\n",
    "# Client ids with top 5 mean payment amount.\n",
    "pd.merge(highest_loan_ids, loans, on='loan_id')['client_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Unique loans given out to clients who joined prior to 2001. I am assuming that prior to means joined on or before 31-Dec-2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_prior_to_2001 = clients.loc[clients['joined'].dt.year < 2001]['client_id']\n",
    "pd.merge(clients_prior_to_2001, loans, on='client_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The mean number of payments missed by clients with a credit score of less than 700 and who have missed more than 50 payments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clients with credit score < 700.\n",
    "clients_poor_cs = clients.loc[clients['credit_score'] < 700]['client_id']\n",
    "# Loan ids of these clients.\n",
    "loan_ids_poor_cs = pd.merge(clients_poor_cs, loans, on='client_id')[['client_id', 'loan_id']]\n",
    "# Payment details of these clients.\n",
    "payments_poor_cs = pd.merge(loan_ids_poor_cs, payments, on='loan_id')\n",
    "# Get count of missed payments by client.\n",
    "missed_payments = payments_poor_cs.loc[payments_poor_cs['missed'] == 1].groupby('client_id').count()['missed']\n",
    "# Get the mean number of missed payments where the missed count > 50. \n",
    "ans3 = missed_payments[missed_payments > 50].mean()\n",
    "print(f'The mean number of payments missed by clients with a credit score of less than 700 and who have missed more than 50 payments = {ans3}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the following visualizations:\n",
    "    \n",
    "1. Create a histogram of the payment amounts. Briefly describe the distribution.\n",
    "2. Produce a line plot the cumulative sum of the number of clients by year.\n",
    "3. Produce a scatter plot of the percentage of payments missed in december for each year in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Histogram of payment amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = payments['payment_amount'].hist(bins=15)\n",
    "ax.set_xlabel('payment amount')\n",
    "ax.set_xlabel('# payments')\n",
    "ignore = ax.set_title('Distribution of payment amounts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution has a long tail on the right hand side. Most paymenta are in the range 500 to 1500. A significant number of them are less than 2000 with a very few of them above it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cumulative sum of number of clients per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients['joined_year'] = clients['joined'].dt.year\n",
    "ax = clients[['client_id', 'joined_year']]. \\\n",
    "            groupby('joined_year'). \\\n",
    "            count(). \\\n",
    "            cumsum(). \\\n",
    "            reset_index(). \\\n",
    "            plot('joined_year', 'client_id',label='# clients')\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('# clients')\n",
    "ignore = ax.set_title('Cumulative sum of clients by year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum on this plot should match the total number of clients. The maximum is 25, so are the number of rows in the data frame <code>clients</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scatter plot of percentage of payments missed in December of every year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments['payment_year'] = payments['payment_date'].dt.year\n",
    "payments['payment_month'] = payments['payment_date'].dt.month\n",
    "dec_count = payments.loc[payments['payment_month'] == 12]\\\n",
    "                        [['loan_id', 'payment_year']]. \\\n",
    "                        groupby('payment_year'). \\\n",
    "                        count(). \\\n",
    "                        rename(columns={'loan_id': 'n_loans'}). \\\n",
    "                        reset_index()\n",
    "dec_missed_count = payments.loc[((payments['payment_month'] == 12) & (payments['missed'] == 1))] \\\n",
    "                               [['loan_id', 'payment_year']]. \\\n",
    "                               groupby('payment_year'). \\\n",
    "                               count(). \\\n",
    "                               rename(columns={'loan_id': 'n_loans_missed'}). \\\n",
    "                               reset_index()\n",
    "\n",
    "X = pd.merge(dec_count, dec_missed_count, on='payment_year')\n",
    "X['pct_missed'] = round(X['n_loans_missed']/X['n_loans'] * 100, 2)\n",
    "ax = X.plot('payment_year', 'pct_missed', label = '% missed')\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('% missed')\n",
    "ignore = ax.set_title('Percentage of payments missed in December')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 - Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model that will predict whether a person does or does not have diabetes. Use the diabetes.csv dataset. The target column in the dataset is \"Outcome\". Assume no features leak information about the target.\n",
    "\n",
    "Your solution should include the below. You may use whichever python libraries you wish to complete the task:\n",
    "1. Feature engineering\n",
    "2. Model fitting and performance evaluation\n",
    "3. A function that takes as arguments: a model, train data, test data, and returns the model's predictions on the test data\n",
    "4. A function that takes a set of predictions and true values and that validates the predictions using appropriate metrics\n",
    "5. Anything else you feel is necessary for modelling or improving the performance of your model\n",
    "\n",
    "\n",
    "__This exercise is intended for you to show your proficiency in machine learning, understanding of the various techniques that can be employed to improve the performance of a model, and your ability to implement those techniques. Please, therefore, show your working at all times. You will be judged more for the above than for the performance of the final model your produce.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data munging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab = pd.read_csv('test_diabetes.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes <code>Insulin</code> and <code>Outcome</code> have a data type <code>object</code>. They need a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab['Insulin'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values are interpreted as strings because a few of them are put as 'Zero'. We must convert them to '0'. Finally, we must make everything numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.loc[all_diab['Insulin'] =='Zero', 'Insulin'] = 0\n",
    "all_diab['Insulin'] = all_diab['Insulin'].apply(lambda s: float(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now look at unique values of <code>Outcome</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab['Outcome'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some values are marked 'N' and 'Y'. We must replace them with '0' and '1' and finally convert all of them to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.loc[all_diab['Outcome'] == 'N', 'Outcome'] = '0'\n",
    "all_diab.loc[all_diab['Outcome'] == 'Y', 'Outcome'] = '1'\n",
    "all_diab['Outcome'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab['Outcome'] = all_diab['Outcome'].apply(lambda s: int(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all values as numbers in the data frame. Yet, there are a few NaNs. How many rows have NaNs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = all_diab[all_diab.applymap(np.isnan).any(True)]\n",
    "\n",
    "print(f'{round(100 * bad_data.shape[0]/all_diab.shape[0], 2)} % of rows have NaNs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A whopping 35% of observations have NaNs. We cannot just ignore all of it. How are the NaNs distributed across attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.shape[0] - all_diab.describe().loc[['count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of NaNs for each attribute are limited. They are atmost 6.6% (51/768). Therefore, we can impute them with medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab = all_diab.fillna(all_diab.median())\n",
    "all_diab.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age has a minimum of $-1$ and a maximum of $200$. Let if find out how many observations have unreasonable ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.loc[((all_diab['Age'] < 0) | (all_diab['Age'] > 95)), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will replace these abnormal values with median of age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.loc[((all_diab['Age'] < 0) | (all_diab['Age'] > 95)), 'Age'] = statistics.median(all_diab['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the values look OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will save the cleaned data for analysis beyond this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.to_csv('clean_diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary examination of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How skewed are the predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.describe().loc[['mean', '50%']] # Compare the mean with the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most means are close to their respective medians, except Insulin. The outliers are likely to emerge from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = all_diab['Insulin'].hist(cumulative=True, bins = 20, density=1)\n",
    "ax.set_xlabel('Insulin')\n",
    "ax.set_ylabel('Cumulative count')\n",
    "ignore = ax.set_title('Cumulative distribution of Insulin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% of subjects have Insulin < 400. I will create a separate data set without them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = all_diab['Insulin'].hist(bins=20)\n",
    "ax.set_xlabel('Insulin')\n",
    "ax.set_ylabel('# cases')\n",
    "ignore = ax.set_title('Distribution of Insulin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insulin values are indeed skewed a lot and we should not expect the mean and the median to be too close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = all_diab.loc[all_diab['Insulin'] < 400]\n",
    "D.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am OK to lose approximately 2.35% of data. Even now the gap between mean and median is large, but let is live with it for the moment.\n",
    "\n",
    "Are there any correlations among the predictors? We will examine using pair plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Xs = ['Pregnancies',\n",
    "          'Glucose',\n",
    "          'BloodPressure',\n",
    "          'SkinThickness',\n",
    "          'Insulin',\n",
    "          'BMI',\n",
    "          'DiabetesPedigreeFunction',\n",
    "          'Age']\n",
    "smat = pd.plotting.scatter_matrix(all_diab[all_Xs], figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no strong correlations among the predictors except for a trend between <code>BMI</code> and <code>SkinThickness</code>. If I have to choose one among them, I would choose <code>BMI</code> because of the short gap between its mean and median. But I will finalize my decision based on t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = 'Outcome'\n",
    "for x in all_Xs:\n",
    "  print(all_diab[[x, Y]].groupby(Y).mean().round(2).transpose())\n",
    "  print(stats.f_oneway(all_diab.loc[all_diab[Y]==0][x], all_diab.loc[all_diab[Y]==1][x]))\n",
    "  print('-' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even ANOVA recommends <code>BMI</code> over <code>SkinThickness</code>. Further, <code>BloodPressure</code> does not seem to have a strong influence on the <code>Outcome</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "I will first define a few helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trn_tst_split(data, trn_pct):\n",
    "    \"\"\"Split the data set into training and test.\n",
    "    \n",
    "        data: the data frame to be split.\n",
    "        trn_pct: % of training data. Must be between 0 and 1.\n",
    "        \n",
    "        Returns a list of two data frames - training and test.\n",
    "    \"\"\"\n",
    "    random.seed(12111842)\n",
    "    N = data.shape[0]\n",
    "    n_train = int(N * trn_pct)\n",
    "    trn_indices = set(random.sample(range(N), n_train))\n",
    "    tst_indices = set(range(N)) - trn_indices\n",
    "    \n",
    "    assert len(trn_indices.intersection(tst_indices)) == 0\n",
    "    assert len(trn_indices) + len(tst_indices) == N\n",
    "    \n",
    "    # Convert them to lists.\n",
    "    trn_indices = [i for i in trn_indices]\n",
    "    tst_indices = [i for i in tst_indices]\n",
    "    \n",
    "    trn_data = data.iloc[trn_indices, :]\n",
    "    tst_data = data.iloc[tst_indices, :]\n",
    "    \n",
    "    assert trn_data.shape[0] + tst_data.shape[0] == data.shape[0]\n",
    "    \n",
    "    return [trn_data, tst_data]\n",
    "\n",
    "\n",
    "def print_cm_results(cm):\n",
    "    \"\"\"Print diagnostics from the confusion matrix.\"\"\"\n",
    "    recall = cm[0, 0]/(cm[0, 0] + cm[1, 0])\n",
    "    precision = cm[0, 0]/(cm[0, 0] + cm[0, 1])\n",
    "    specificity = cm[1, 1]/(cm[1, 0] + cm[1, 1])\n",
    "    f1_score = 2*recall*precision/(recall + precision)\n",
    "    accuracy = np.trace(cm)/np.sum(cm)\n",
    "    \n",
    "    print(f'% +ves correctly predicted (recall) = {round(recall * 100, 2)}')\n",
    "    print(f'% +ves detected out of all (precision) = {round(precision * 100, 2)}')\n",
    "    print(f'% -ves detected out of all (specificity) = {round(specificity * 100, 2)}')\n",
    "    print(f'f1 score = {round(f1_score, 2)}')\n",
    "    print(f'accuracy = {round(accuracy * 100, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I next list the 'formulae' (similar to the ones used in R) used to define the linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First model takes all X's, ignoring the preliminary investigation.\n",
    "f_v0 = 'Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age'\n",
    "# We know that blood pressure does not matter and skin thickness is correlated to BMI. We drop them.\n",
    "f_v1 = 'Outcome ~ Pregnancies + Glucose + Insulin + BMI + DiabetesPedigreeFunction + Age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_matrices(D, formula):\n",
    "    return dmatrices(formula, data=D, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data, tst_data = trn_tst_split(D, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model matrices for model with version 0.\n",
    "yn_v0, Xn_v0 = get_model_matrices(trn_data, f_v0)\n",
    "# Training model matrices for model with version 1.\n",
    "yn_v1, Xn_v1 = get_model_matrices(trn_data, f_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the two models and get their confusion matrices on the **training** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v0 = sm.Logit(yn_v0, Xn_v0)\n",
    "results_v0 = model_v0.fit()\n",
    "cm_v0 = results_v0.pred_table()\n",
    "print(results_v0.summary())\n",
    "\n",
    "print()\n",
    "print('-' * 80)\n",
    "print()\n",
    "\n",
    "model_v1 = sm.Logit(yn_v1, Xn_v1)\n",
    "results_v1 = model_v1.fit()\n",
    "cm_v1 = results_v1.pred_table()\n",
    "print(results_v1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key observations in model version 0.\n",
    "1. The coefficients of <code>Insulin</code> and <code>SkinThickness</code> are not statistically significant.\n",
    "2. The pseudo-R2 for the model is 26%. Not bad for a biological system.\n",
    "\n",
    "Key observations in model version 1.\n",
    "1. <code>Insulin</code> and <code>Age</code> must be dropped.\n",
    "2. The pseudo-R2 has dropped a bit but not too alarmingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that blood pressure does not matter and skin thickness is correlated to BMI. We drop them.\n",
    "f_v2 = 'Outcome ~ Pregnancies + Glucose + BMI + DiabetesPedigreeFunction'\n",
    "# Training model matrices for model with version 2.\n",
    "yn_v2, Xn_v2 = get_model_matrices(trn_data, f_v2)\n",
    "model_v2 = sm.Logit(yn_v2, Xn_v2)\n",
    "results_v2 = model_v2.fit()\n",
    "cm_v2 = results_v2.pred_table()\n",
    "print(results_v2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All regression coefficients are significant but pseudo-R2 has dropped by 0.5%. Let us now look at the confusion matrices on the **training** data for all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all confusion matrices\n",
    "cms = [cm_v0, cm_v1, cm_v2]\n",
    "for i, cm in enumerate(cms):\n",
    "    print(f'Confusion matrix for version {i}:')\n",
    "    print_cm_results(cm)\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 0 seems to be the best on the training data. We will now find out how these model fare on the test data. \n",
    "\n",
    "But before we do that, we need a helper function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_to_outcome(y, threshold = 0.5):\n",
    "    \"\"\"Converts probability to a class depending on the threshold.\"\"\"\n",
    "    if y < threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def build_cm(yt, yp):\n",
    "    \"\"\"Generates confusion matrix from actual and predicted values.\"\"\"\n",
    "    yt['predicted'] = [prob_to_outcome(y) for y in yp]\n",
    "    yt.columns = ['actual', 'predicted']\n",
    "    yt['actual'] = yt['actual'].apply(lambda f: int(f))\n",
    "    cm = pd.crosstab(yt['actual'], yt['predicted']).to_numpy()\n",
    "    \n",
    "    return cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the design matrices.\n",
    "yt_v0, Xt_v0 = get_model_matrices(tst_data, f_v0)\n",
    "yt_v1, Xt_v1 = get_model_matrices(tst_data, f_v1)\n",
    "yt_v2, Xt_v2 = get_model_matrices(tst_data, f_v2)\n",
    "\n",
    "# Get the predictions.\n",
    "yp_v0 = results_v0.predict(Xt_v0)\n",
    "yp_v1 = results_v1.predict(Xt_v1)\n",
    "yp_v2 = results_v2.predict(Xt_v2)\n",
    "\n",
    "cm_v0 = build_cm(yt_v0, yp_v0)\n",
    "cm_v1 = build_cm(yt_v1, yp_v1)\n",
    "cm_v2 = build_cm(yt_v2, yp_v2)\n",
    "\n",
    "# Print all confusion matrices\n",
    "cms = [cm_v0, cm_v1, cm_v2]\n",
    "for i, cm in enumerate(cms):\n",
    "    print(f'Confusion matrix for version {i}:')\n",
    "    print_cm_results(cm)\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2 seems to better than the previous ones. We choose it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before closing, I will write a function asked in point 3. Our model and the design matrices depend on the formula. Therefore, instead of passing model as the first parameter, we pass the formula, a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_on_test_data(formula, train, test, threshold = 0.5):\n",
    "    \"\"\"Get predictions of a model on test data.\n",
    "    \n",
    "        formula:   a string describing the linear model.\n",
    "        train:     the training data set.\n",
    "        test:      the test data set.\n",
    "        threshold: a cut off applied to the probabilities to decide the class.\n",
    "    \"\"\"\n",
    "    yn, Xn = get_model_matrices(train, formula)\n",
    "    yt, Xt = get_model_matrices(test, formula)\n",
    "    \n",
    "    model = sm.Logit(yn, Xn)\n",
    "    results = model.fit()\n",
    "    yp = results.predict(Xt)\n",
    "    \n",
    "    return yp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test this function on version 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp2 = run_model_on_test_data(f_v2, trn_data, tst_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check it the results match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert max(abs(yp2 - yp_v2)) == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggested next steps:\n",
    "1. The specificity of the model is 57%. It means that 43% of the cases classified as diabetic turn out to be not so. I think in this case, it is OK to suspect someone of being diabetic and putting her on medications than otherwise. Do we need to adjust the threshold to decrease specificity and reduce the false positives? (False positive in this case means that the model declared that the person is not diabetic but she turned out to be one.)\n",
    "2. I have used one split between training and test data. Ideally, one must cross-validate extensively. It is possible to do 30 cross-validations using 'hold-25' strategy. I do not know if this can be done automatically in Python. In R it is just a function call.\n",
    "3. I would like to see how Naive Bayes performs on this data. Of the four predictors in the version 2 of the model, two appear Gaussian but <code>Pregnancy</code> and <code>DiabetesPedigreeFunction</code> are conspicuously non-Gaussian. I don't know if I can use a Naive Bayesian classifier on such a combination of predictors.\n",
    "4. It is always worth the efforts to check if a random forest classifier does a better job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

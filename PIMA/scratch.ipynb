{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the three files: clients.csv, loans.csv, payments.csv. These files are related by the following:\n",
    "1. The clients file is the parent of the loans file. Each client can have multiple distinct loans. The client_id column links the two files\n",
    "2. The loans file is the child of the clients file and the parent of the payments file. Each loan can have multiple distinct payments associated with it. The loan_id column links the two files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic packages.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data sets into data frames.\n",
    "clients = pd.read_csv('clients.csv')\n",
    "loans = pd.read_csv('loans.csv')\n",
    "payments = pd.read_csv('payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check of the structure of the data.\n",
    "x = clients.info()\n",
    "x = loans.info()\n",
    "x = payments.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clients.shape)\n",
    "print(loans.shape)\n",
    "print(payments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above datasets, answer the following questions. Show the steps taken to produce your final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Give the 5 client IDs with the highest mean payment amount\n",
    "2. How many unique loans have been given out to clients who joined prior to 2001?\n",
    "3. What is the mean number of payments missed by clients with a credit score of less than 700 and who have missed more than 50 payments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_ids with highest mean payment amount.\n",
    "highest_loan_ids = payments[['loan_id', 'payment_amount']]. \\\n",
    "                   groupby('loan_id'). \\\n",
    "                   mean(). \\\n",
    "                   sort_values(ascending=False, by='payment_amount'). \\\n",
    "                   head(5)\n",
    "# Client ids with top 5 mean payment amount.\n",
    "pd.merge(highest_loan_ids, loans, on='loan_id')['client_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the attribute 'joined' in the dataframe clients in datatime format.\n",
    "clients['joined'] = pd.to_datetime(clients['joined'])\n",
    "clients_prior_to_2001 = clients.loc[clients['joined'].dt.year <= 2001]['client_id']\n",
    "pd.merge(clients_prior_to_2001, loans, on='client_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clients with credit score < 700.\n",
    "clients_poor_cs = clients.loc[clients['credit_score'] < 700]['client_id']\n",
    "# Loan ids of these clients.\n",
    "loan_ids_poor_cs = pd.merge(clients_poor_cs, loans, on='client_id')[['client_id', 'loan_id']]\n",
    "# Payment details of these clients.\n",
    "payments_poor_cs = pd.merge(loan_ids_poor_cs, payments, on='loan_id')\n",
    "# Get count of missed payments by client.\n",
    "missed_payments = payments_poor_cs.loc[payments_poor_cs['missed'] == 1].groupby('client_id').count()['missed']\n",
    "# Get the mean number of missed payments where the missed count > 50. \n",
    "missed_payments[missed_payments > 50].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the following visualizations:\n",
    "    \n",
    "1. Create a histogram of the payment amounts. Briefly describe the distribution.\n",
    "2. Produce a line plot the cumulative sum of the number of clients by year.\n",
    "3. Produce a scatter plot of the percentage of payments missed in december for each year in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments['payment_amount'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients['joined_year'] = clients['joined'].dt.year\n",
    "ax = clients[['client_id', 'joined_year']].groupby('joined_year').count().cumsum().reset_index().plot('joined_year', 'client_id')\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('# clients')\n",
    "ax.set_title('Cumulative sum of clients by year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments['payment_date'] = pd.to_datetime(payments['payment_date'])\n",
    "payments['payment_year'] = payments['payment_date'].dt.year\n",
    "payments['payment_month'] = payments['payment_date'].dt.month\n",
    "dec_count = payments.loc[payments['payment_month'] == 12][['loan_id', 'payment_year']].groupby('payment_year').count().rename(columns={'loan_id': 'n_loans'}).reset_index()\n",
    "#\n",
    "dec_missed_count = payments.loc[((payments['payment_month'] == 12) & (payments['missed'] == 1))][['loan_id', 'payment_year']].groupby('payment_year').count().rename(columns={'loan_id': 'n_loans_missed'}).reset_index()\n",
    "\n",
    "X = pd.merge(dec_count, dec_missed_count, on='payment_year')\n",
    "X['pct_missed'] = round(X['n_loans_missed']/X['n_loans'] * 100, 2)\n",
    "ax = X.plot('payment_year', 'pct_missed')\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('% missed')\n",
    "ax.set_title('Percentage of payments missed in December')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 - Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model that will predict whether a person does or does not have diabetes. Use the diabetes.csv dataset. The target column in the dataset is \"Outcome\". Assume no features leak information about the target.\n",
    "\n",
    "Your solution should include the below. You may use whichever python libraries you wish to complete the task:\n",
    "1. Feature engineering\n",
    "2. Model fitting and performance evaluation\n",
    "3. A function that takes as arguments: a model, train data, test data, and returns the model's predictions on the test data\n",
    "4. A function that takes a set of predictions and true values and that validates the predictions using appropriate metrics\n",
    "5. Anything else you feel is necessary for modelling or improving the performance of your model\n",
    "\n",
    "\n",
    "__This exercise is intended for you to show your proficiency in machine learning, understanding of the various techniques that can be employed to improve the performance of a model, and your ability to implement those techniques. Please, therefore, show your working at all times. You will be judged more for the above than for the performance of the final model your produce.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data, conduct a preliminary examination\n",
    "all_diab = pd.read_csv('test_diabetes.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is Insulin not numeric?\n",
    "all_diab['Insulin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must replace 'Zero' in the column 'Insulin' with '0'\n",
    "all_diab.loc[all_diab['Insulin'] =='Zero', 'Insulin'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Insulin' to float\n",
    "all_diab['Insulin'] = all_diab['Insulin'].apply(lambda s: float(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is 'Outcome' and object?\n",
    "all_diab['Outcome'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'N' with '0' and 'Y' with '1'\n",
    "all_diab.loc[all_diab['Outcome'] == 'N', 'Outcome'] = '0'\n",
    "all_diab.loc[all_diab['Outcome'] == 'Y', 'Outcome'] = '1'\n",
    "all_diab['Outcome'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert '1' and '0' to respective integers\n",
    "all_diab['Outcome'] = all_diab['Outcome'].apply(lambda s: int(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By this stage, we have cleaned the data. All values are numeric. There are a few 'NaN's but they need a \n",
    "# separate consideration.\n",
    "all_diab[all_diab.applymap(np.isnan).any(True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of NaN's in each column\n",
    "C = all_diab.describe().loc[['count']]\n",
    "C = (all_diab.shape[0] - C)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do the medians look like?\n",
    "all_diab.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us impute all the NaN's with respective medians.\n",
    "all_diab = all_diab.fillna(all_diab.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the data look good now?\n",
    "all_diab.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the population of each class\n",
    "all_diab.groupby('Outcome').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How skewed are the X's?\n",
    "all_diab.describe().loc[['mean', '50%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a huge difference between mean and median of Insulin. The data seems to be skewed to the right.\n",
    "all_diab['Insulin'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Xs = ['Pregnancies',\n",
    " 'Glucose',\n",
    " 'BloodPressure',\n",
    " 'SkinThickness',\n",
    " 'Insulin',\n",
    " 'BMI',\n",
    " 'DiabetesPedigreeFunction',\n",
    " 'Age']\n",
    "sm = pd.plotting.scatter_matrix(all_diab[all_Xs], figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only BMI and SkinThickness seem to be correlated. Quite naturally!!\n",
    "# Next run t-test to check if the means of X's in groups 0 and 1 are similar.\n",
    "from scipy.stats import stats\n",
    "\n",
    "Y = 'Outcome'\n",
    "for x in all_Xs:\n",
    "  print(all_diab[[x, Y]].groupby(Y).mean().round(2).transpose())\n",
    "  print(stats.f_oneway(all_diab.loc[all_diab[Y]==0][x], all_diab.loc[all_diab[Y]==1][x]))\n",
    "  print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkinThickness and BloodPressure are not significantly different in diabetics and non-diabetics. We can drop these\n",
    "# variables. We will now try a logistic regression model.\n",
    "import random\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def get_split(N, p):\n",
    "    \"\"\" Split data indexed 0 to (N-1) into training and test.\"\"\"\n",
    "    n_train = int(N * p)\n",
    "    train_indices = set(random.sample(range(N), n_train))\n",
    "    test_indices = set(range(N)) - train_indices\n",
    "    \n",
    "    assert len(train_indices.intersection(test_indices)) == 0\n",
    "    assert len(train_indices) + len(test_indices) == N\n",
    "    \n",
    "    # Return both as lists\n",
    "    return [[i for i in train_indices], [i for i in test_indices]]\n",
    "\n",
    "train_indices, test_indices = get_split(all_diab.shape[0], 0.70)\n",
    "\n",
    "trn_data = all_diab.iloc[train_indices, :]\n",
    "tst_data = all_diab.iloc[test_indices, :]\n",
    "\n",
    "assert trn_data.shape[0] + tst_data.shape[0] == all_diab.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm_results(cm):\n",
    "    \"\"\"Print diagnostics from the confusion matrix\"\"\"\n",
    "    recall = cm[0, 0]/(cm[0, 0] + cm[1, 0])\n",
    "    precision = cm[0, 0]/(cm[0, 0] + cm[0, 1])\n",
    "    specificity = cm[1, 1]/(cm[1, 0] + cm[1, 1])\n",
    "    f1_score = 2*recall*precision/(recall + precision)\n",
    "    accuracy = np.trace(cm)/np.sum(cm)\n",
    "    \n",
    "    print(f'% +ves correctly predicted = {round(recall * 100, 2)}')\n",
    "    print(f'% +ves detected out of all = {round(precision * 100, 2)}')\n",
    "    print(f'% -ves detected out of all = {round(specificity * 100, 2)}')\n",
    "    print(f'f1 score = {round(f1_score, 2)}')\n",
    "    print(f'accuracy = {round(accuracy * 100, 2)}')\n",
    "    \n",
    "print_cm_results(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us try using all X's.\n",
    "def get_model_matrices_v0(D):\n",
    "    return dmatrices('Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age', \\\n",
    "                     data = D, return_type='dataframe')\n",
    "\n",
    "# Training model matrices\n",
    "yn, Xn = get_model_matrices_v0(trn_data)\n",
    "yt, Xt = get_model_matrices_v0(tst_data)\n",
    "\n",
    "# Version 0 of the model.\n",
    "model_v0 = sm.Logit(yn, Xn)\n",
    "results_v0 = model_v0.fit()\n",
    "print(results_v0.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data performance\n",
    "cm_v0 = results_v0.pred_table()\n",
    "print(cm_v0)\n",
    "print_cm_results(cm_v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_matrices_v1(D):\n",
    "    return dmatrices('Outcome ~ Pregnancies + Glucose + Insulin + BMI + DiabetesPedigreeFunction + Age', \\\n",
    "                    data = D, return_type='dataframe')\n",
    "\n",
    "# Training model matrices\n",
    "yn, Xn = get_model_matrices_v1(trn_data)\n",
    "yt, Xt = get_model_matrices_v1(tst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1 of the model.\n",
    "model_v1 = sm.Logit(yn, Xn)\n",
    "results_v1 = model_v1.fit()\n",
    "print(results_v1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data performance\n",
    "cm_v1 = results_v1.pred_table()\n",
    "print(cm_v1)\n",
    "print_cm_results(cm_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quite surprisingly, only Pregnancies and Glucose remain!!\n",
    "def get_model_matrices_v2(D):\n",
    "    return dmatrices('Outcome ~ Pregnancies + Glucose + BMI + DiabetesPedigreeFunction', \\\n",
    "                     data = D, return_type='dataframe')\n",
    "\n",
    "# Training model matrices\n",
    "yn, Xn = get_model_matrices_v2(trn_data)\n",
    "yt, Xt = get_model_matrices_v2(tst_data)\n",
    "\n",
    "# Version 2 of the model.\n",
    "model_v2 = sm.Logit(yn, Xn)\n",
    "results_v2 = model_v2.fit()\n",
    "print(results_v2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data performance\n",
    "cm_v2 = results_v2.pred_table()\n",
    "print(cm_v2)\n",
    "print_cm_results(cm_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all confusion matrices\n",
    "cms = [cm_v0, cm_v1, cm_v2]\n",
    "for i, cm in enumerate(cms):\n",
    "    print(f'Confusion matrix for version {i}:')\n",
    "    print_cm_results(cm)\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going by the scores on training data, version 1 looks to be the best.\n",
    "# We will check how it does on the test data.\n",
    "yt, Xt = get_model_matrices_v1(tst_data)\n",
    "yt_pred = results_v1.predict(Xt)\n",
    "\n",
    "def prob_to_outcome(y, threshold = 0.5):\n",
    "    if y < threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "yt['predicted'] = [prob_to_outcome(y) for y in yt_pred]\n",
    "yt.columns = ['actual', 'predicted']\n",
    "yt['actual'] = yt['actual'].apply(lambda f: int(f))\n",
    "tcm_v1 = pd.crosstab(yt['actual'], yt['predicted']).to_numpy()\n",
    "print(f'Test Confusion matrix for version 1:')\n",
    "print_cm_results(tcm_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
